#%% Visualize data Alex Foxen
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("Cleaned/William Alex Foxen Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)

plt.figure(figsize=(18,8))
plt.title("Alex Foxen Live Earning")
df["Earning increment"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Total Earning USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Alex Foxen Ranking")
df["Ranking"].plot.hist(bins = 1000)
plt.xlim([0,100])
plt.xlabel("Placement", fontsize = 18)
plt.xticks(np.arange(0,100,1), rotation=90)
plt.ylabel("Frequency", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Alex Foxen Buy in")
df["Buy-in"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Buy in USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Alex Foxen Earning in Tournament")
df["int earning"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Prize USD", fontsize = 18)

plt.figure(figsize=(12, 10))
df_coor = df.drop("Earning increment", axis=1)
plt.plot()
sns.heatmap(df_coor.corr(), annot=True, cmap='summer')
plt.title('Correlation of Poker Player')
#Model building
import math
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
df = pd.read_csv("Cleaned/William Alex Foxen Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)
#Create data frame with only close price
data = df.filter(["Earning increment"])
#Convert to numpy arr
dataset = data.values
#Get number of rows to train the model
training_data_len = math.ceil(len(dataset) * .79)

#Scale data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#Create training data set
#Create the scaled training data set
train_data = scaled_data[0:training_data_len,:]
#Split the data into x and y train
x_train = []
y_train = []

for i in range(40,len(train_data)):
    x_train.append(train_data[i-40:i,0])
    y_train.append(train_data[i,0])

#Convert the x and y train to nummpy array
x_train,y_train = np.array(x_train), np.array(y_train)

#Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))

#Build the LSTM model
model = Sequential()
model.add(LSTM(50,return_sequences=True, input_shape = (x_train.shape[1],1)))
model.add(LSTM(50,return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

#Run the model
model.compile(optimizer ='adam', loss = 'mean_squared_error')

#Train model
model.fit(x_train,y_train, batch_size=1,epochs=1)

#Create test data set
#Create new array containing scaled value
test_data = scaled_data[training_data_len - 40:,:]

#Create data set x and y test
x_test = []
y_test = dataset[training_data_len:,:]

for i in range(40,len(test_data)):
    x_test.append(test_data[i-40:i,0])
    
#convert data to a numpy array
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))

#get the models predicted price value
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#Get RMSE
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))


#Plot
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions
plt.figure(figsize=(16,8))
plt.title("Model")
plt.xlabel("Date")
plt.ylabel("Total Earning USD")
plt.plot(train["Earning increment"])
plt.plot(valid[["Earning increment", "Predictions"]])
plt.legend(["Train", "Valid","Predictions"], loc = "lower right")
plt.show()

#%% Visualize data Mikita Bodyakovsky
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("Cleaned/Mikita Bodyakovsky Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)

plt.figure(figsize=(18,8))
plt.title("Mikita Bodyakovsky Live Earning")
df["Earning increment"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Total Earning USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Mikita Bodyakovsky Ranking")
df["Ranking"].plot.hist(bins = 1000)
plt.xlim([0,100])
plt.xlabel("Placement", fontsize = 18)
plt.xticks(np.arange(0,100,1), rotation=90)
plt.ylabel("Frequency", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Mikita Bodyakovsky Buy in")
df["Buy-in"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Buy in USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Mikita Bodyakovsky Earning in Tournament")
df["int earning"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Prize USD", fontsize = 18)

plt.figure(figsize=(12, 10))
df_coor = df.drop("Earning increment", axis=1)
plt.plot()
sns.heatmap(df_coor.corr(), annot=True, cmap='summer')
plt.title('Correlation of Poker Player')
#Model building
import math
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
df = pd.read_csv("Cleaned/Mikita Bodyakovsky Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)
#Create data frame with only close price
data = df.filter(["Earning increment"])
#Convert to numpy arr
dataset = data.values
#Get number of rows to train the model
training_data_len = math.ceil(len(dataset) * .81)

#Scale data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#Create training data set
#Create the scaled training data set
train_data = scaled_data[0:training_data_len,:]
#Split the data into x and y train
x_train = []
y_train = []

for i in range(40,len(train_data)):
    x_train.append(train_data[i-40:i,0])
    y_train.append(train_data[i,0])

#Convert the x and y train to nummpy array
x_train,y_train = np.array(x_train), np.array(y_train)

#Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))

#Build the LSTM model
model = Sequential()
model.add(LSTM(50,return_sequences=True, input_shape = (x_train.shape[1],1)))
model.add(LSTM(50,return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

#Run the model
model.compile(optimizer ='adam', loss = 'mean_squared_error')

#Train model
model.fit(x_train,y_train, batch_size=1,epochs=1)

#Create test data set
#Create new array containing scaled value
test_data = scaled_data[training_data_len - 40:,:]

#Create data set x and y test
x_test = []
y_test = dataset[training_data_len:,:]

for i in range(40,len(test_data)):
    x_test.append(test_data[i-40:i,0])
    
#convert data to a numpy array
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))

#get the models predicted price value
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#Get RMSE
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))


#Plot
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions
plt.figure(figsize=(16,8))
plt.title("Model")
plt.xlabel("Date")
plt.ylabel("Total Earning USD")
plt.plot(train["Earning increment"])
plt.plot(valid[["Earning increment", "Predictions"]])
plt.legend(["Train", "Valid","Predictions"], loc = "lower right")
plt.show()

#%% Visualize data Espen Uhlen Jørstad
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("Cleaned/Espen Uhlen Jørstad Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)

plt.figure(figsize=(18,8))
plt.title("Espen Uhlen Jørstad Live Earning")
df["Earning increment"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Total Earning USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Espen Uhlen Jørstad Ranking")
df["Ranking"].plot.hist(bins = 1000)
plt.xlim([0,100])
plt.xlabel("Placement", fontsize = 18)
plt.xticks(np.arange(0,100,1), rotation=90)
plt.ylabel("Frequency", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Espen Uhlen Jørstad Buy in")
df["Buy-in"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Buy in USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Espen Uhlen Jørstad Earning in Tournament")
df["int earning"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Prize USD", fontsize = 18)

plt.figure(figsize=(12, 10))
df_coor = df.drop("Earning increment", axis=1)
plt.plot()
sns.heatmap(df_coor.corr(), annot=True, cmap='summer')
plt.title('Correlation of Poker Player')

#Model building
import math
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
df = pd.read_csv("Cleaned/Espen Uhlen Jørstad Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)
#Create data frame with only close price
data = df.filter(["Earning increment"])
#Convert to numpy arr
dataset = data.values
#Get number of rows to train the model
training_data_len = math.ceil(len(dataset) * .70)

#Scale data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#Create training data set
#Create the scaled training data set
train_data = scaled_data[0:training_data_len,:]
#Split the data into x and y train
x_train = []
y_train = []

for i in range(15,len(train_data)):
    x_train.append(train_data[i-15:i,0])
    y_train.append(train_data[i,0])

#Convert the x and y train to nummpy array
x_train,y_train = np.array(x_train), np.array(y_train)

#Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))

#Build the LSTM model
model = Sequential()
model.add(LSTM(50,return_sequences=True, input_shape = (x_train.shape[1],1)))
model.add(LSTM(50,return_sequences= False))
model.add(Dense(25, activation='relu'))
model.add(Dense(1, activation='relu'))

#Run the model
model.compile(optimizer ='adam', loss = 'mean_squared_error')

#Train model
model.fit(x_train,y_train, batch_size=1,epochs=1)

#Create test data set
#Create new array containing scaled value
test_data = scaled_data[training_data_len - 15:,:]

#Create data set x and y test
x_test = []
y_test = dataset[training_data_len:,:]

for i in range(15,len(test_data)):
    x_test.append(test_data[i-15:i,0])
    
#convert data to a numpy array
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))

#get the models predicted price value
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#Get RMSE
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))


#Plot
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions
plt.figure(figsize=(16,8))
plt.title("Model")
plt.xlabel("Date")
plt.ylabel("Total Earning USD")
plt.plot(train["Earning increment"])
plt.plot(valid[["Earning increment", "Predictions"]])
plt.legend(["Train", "Valid","Predictions"], loc = "lower right")
plt.show()

#%% Visualize data Daniel Negreanu
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv("Cleaned/Daniel Negreanu Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)

plt.figure(figsize=(18,8))
plt.title("Daniel Negreanu Live Earning")
df["Earning increment"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Total Earning USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Daniel Negreanu Ranking")
df["Ranking"].plot.hist(bins = 1000)
plt.xlim([0,100])
plt.xlabel("Placement", fontsize = 18)
plt.xticks(np.arange(0,100,1), rotation=90)
plt.ylabel("Frequency", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Daniel Negreanu Buy in")
df["Buy-in"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Buy in USD", fontsize = 18)

plt.figure(figsize=(18,8))
plt.title("Daniel Negreanu Earning in Tournament")
df["int earning"].plot()
plt.xlabel("Date", fontsize = 18)
plt.ylabel("Prize USD", fontsize = 18)

plt.figure(figsize=(12, 10))
df_coor = df.drop("Earning increment", axis=1)
plt.plot()
sns.heatmap(df_coor.corr(), annot=True, cmap='summer')
plt.title('Correlation of Poker Player')


#Model building
import math
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
df = pd.read_csv("Cleaned/Daniel Negreanu Cleaned.csv", index_col=False)
df["Date"] = pd.to_datetime(df["Date"])
df.set_index("Date", inplace=True)
#Create data frame with only close price
data = df.filter(["Earning increment"])
#Convert to numpy arr
dataset = data.values
#Get number of rows to train the model
training_data_len = math.ceil(len(dataset) * .70)

#Scale data
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#Create training data set
#Create the scaled training data set
train_data = scaled_data[0:training_data_len,:]
#Split the data into x and y train
x_train = []
y_train = []

for i in range(30,len(train_data)):
    x_train.append(train_data[i-30:i,0])
    y_train.append(train_data[i,0])

#Convert the x and y train to nummpy array
x_train,y_train = np.array(x_train), np.array(y_train)

#Reshape the data
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))

#Build the LSTM model
model = Sequential()
model.add(LSTM(50,return_sequences=True, input_shape = (x_train.shape[1],1)))
model.add(LSTM(50,return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

#Run the model
model.compile(optimizer ='adam', loss = 'mean_squared_error')

#Train model
model.fit(x_train,y_train, batch_size=1,epochs=1)

#Create test data set
#Create new array containing scaled value
test_data = scaled_data[training_data_len - 30:,:]

#Create data set x and y test
x_test = []
y_test = dataset[training_data_len:,:]

for i in range(30,len(test_data)):
    x_test.append(test_data[i-30:i,0])
    
#convert data to a numpy array
x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1], 1))

#get the models predicted price value
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

#Get RMSE
rmse=np.sqrt(np.mean(((predictions- y_test)**2)))


#Plot
train = data[:training_data_len]
valid = data[training_data_len:]
valid["Predictions"] = predictions
plt.figure(figsize=(16,8))
plt.title("Model")
plt.xlabel("Date")
plt.ylabel("Total Earning USD")
plt.plot(train["Earning increment"])
plt.plot(valid[["Earning increment", "Predictions"]])
plt.legend(["Train", "Valid","Predictions"], loc = "lower right")
plt.show()
